dataloader:
  batch_size: 4
  data_root: DATA/CUB-200
  num_workers: 4
  train_datasets:
  - params:
      data_root: DATA/CUB-200
      drop_caption_rate: 0.0
      im_preprocessor_config:
        params:
          phase: train
          size: 256
        target: image_synthesis.data.utils.image_preprocessor.DalleTransformerPreprocessor
      phase: train
    target: image_synthesis.data.cub200_dataset.Cub200Dataset
  validation_datasets:
  - params:
      data_root: DATA/CUB-200
      im_preprocessor_config:
        params:
          phase: val
          size: 256
        target: image_synthesis.data.utils.image_preprocessor.DalleTransformerPreprocessor
      phase: test
    target: image_synthesis.data.cub200_dataset.Cub200Dataset
model:
  params:
    condition_codec_config:
      params:
        add_start_and_end: true
        clip_embedding: false
        context_length: 77
        pad_value: 0
        tokenizer_config:
          params:
            end_idx: 49152
          target: image_synthesis.modeling.modules.clip.simple_tokenizer.SimpleTokenizer
        with_mask: true
      target: image_synthesis.modeling.codecs.text_codec.tokenize.Tokenize
    condition_info:
      key: text
    content_codec_config:
      params:
        ckpt_path: OUTPUT/pretrained_model/taming_dvae/taming_f8_8192_openimages_last.pth
        config_path: OUTPUT/pretrained_model/taming_dvae/taming_f8_8192_openimages.yaml
        mapping_path: ./help_folder/statistics/taming_vqvae_2887.pt
        num_tokens: 8192
        quantize_number: 2887
        token_shape:
        - 32
        - 32
        trainable: false
      target: image_synthesis.modeling.codecs.image_codec.taming_gumbel_vqvae.TamingGumbelVQVAE
    content_info:
      key: image
    diffusion_config:
      params:
        adaptive_auxiliary_loss: true
        alpha_init_type: alpha1
        auxiliary_loss_weight: 0.0005
        condition_emb_config:
          params:
            additional_last_embedding: false
            clip_name: ViT-B/32
            embed_dim: 512
            keep_seq_len_dim: false
            normalize: true
            num_embed: 49408
            pick_last_embedding: false
          target: image_synthesis.modeling.embeddings.clip_text_embedding.CLIPTextEmbedding
        content_emb_config:
          params:
            embed_dim: 1024
            num_embed: 2887
            pos_emb_type: embedding
            spatial_size: !!python/tuple
            - 32
            - 32
            trainable: true
          target: image_synthesis.modeling.embeddings.dalle_mask_image_embedding.DalleMaskImageEmbedding
        diffusion_step: 100
        mask_weight:
        - 1
        - 1
        transformer_config:
          params:
            attn_pdrop: 0.0
            attn_type: selfcross
            block_activate: GELU2
            condition_dim: 512
            condition_seq_len: 77
            content_seq_len: 1024
            content_spatial_size:
            - 32
            - 32
            mlp_hidden_times: 4
            n_embd: 1024
            n_head: 16
            n_layer: 19
            resid_pdrop: 0.0
            timestep_type: adalayernorm
          target: image_synthesis.modeling.transformers.transformer_utils.Text2ImageTransformer
      target: image_synthesis.modeling.transformers.diffusion_transformer.DiffusionTransformer
  target: image_synthesis.modeling.models.dalle.DALLE
solver:
  adjust_lr: none
  base_lr: 3.0e-06
  clip_grad_norm:
    params:
      end_iteration: 5000
      max_norm: 0.5
      start_iteration: 0
    target: image_synthesis.engine.clip_grad_norm.ClipGradNorm
  ema:
    decay: 0.99
    device: cpu
    update_interval: 25
  max_epochs: 400
  optimizers_and_schedulers:
  - name: none
    optimizer:
      params:
        betas: !!python/tuple
        - 0.9
        - 0.96
        weight_decay: 0.045
      target: torch.optim.AdamW
    scheduler:
      params:
        factor: 0.5
        min_lr: 1.0e-06
        patience: 25000
        threshold: 0.1
        threshold_mode: rel
        warmup: 1000
        warmup_lr: 0.00045
      step_iteration: 1
      target: image_synthesis.engine.lr_scheduler.ReduceLROnPlateauWithWarmup
  print_specific_things: true
  sample_iterations: epoch
  save_epochs: 30
  validation_epochs: 400
